{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read both the images of the face and the glasses\n",
    "image = cv2.imread('test_images/1.JPG')\n",
    "glass_img = cv2.imread('glass_mask.png')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# cv2.imshow('Lets wear Glasses', glass_img)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = []\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over the face detected\n",
    "for (x, y, w, h) in faces:\n",
    "\n",
    "    # create two Regions of Interest.\n",
    "    roi_gray = gray[y:y + h, x:x + w]\n",
    "    roi_color = image[y:y + h, x:x + w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "    # Store the coordinates of eyes in the image to the 'center' array\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        centers.append((x + int(ex + 0.5 * ew), y + int(ey + 0.5 * eh)))\n",
    "\n",
    "if len(centers) > 0:\n",
    "    # change the given value of 2.15 according to the size of the detected face\n",
    "    glasses_width = 2.16 * abs(centers[1][0] - centers[0][0])\n",
    "    overlay_img = np.ones(image.shape, np.uint8) * 255\n",
    "    h, w = glass_img.shape[:2]\n",
    "    scaling_factor = glasses_width / w\n",
    "\n",
    "    overlay_glasses = cv2.resize(glass_img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    x = centers[0][0] if centers[0][0] < centers[1][0] else centers[1][0]\n",
    "\n",
    "    # The x and y variables below depend upon the size of the detected face.\n",
    "    x -= 0.25 * overlay_glasses.shape[1]\n",
    "    y += 1.1 * overlay_glasses.shape[0]\n",
    "\n",
    "    # Slice the height, width of the overlay image.\n",
    "    h, w = overlay_glasses.shape[:2]\n",
    "    overlay_img[int(y):int(y + h), int(x):int(x + w)] = overlay_glasses\n",
    "\n",
    "    # Create a mask and generate it's inverse.\n",
    "    gray_glasses = cv2.cvtColor(overlay_img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(gray_glasses, 110, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    temp = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    temp2 = cv2.bitwise_and(overlay_img, overlay_img, mask=mask_inv)\n",
    "    final_img = cv2.add(temp, temp2)\n",
    "\n",
    "    # imS = cv2.resize(final_img, (1366, 768))\n",
    "    cv2.imshow('Lets wear Glasses', final_img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping entire code for all images in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'test_images/' #directory\n",
    "glass_img = cv2.imread('glass_mask.png')\n",
    "SAVE_DIR = 'output/' #output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(DIR):\n",
    "    image = cv2.imread(os.path.join(DIR,file))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    centers = []\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    # iterating over the face detected\n",
    "    for (x, y, w, h) in faces:\n",
    "\n",
    "        # create two Regions of Interest.\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = image[y:y + h, x:x + w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        # Store the coordinates of eyes in the image to the 'center' array\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            centers.append((x + int(ex + 0.5 * ew), y + int(ey + 0.5 * eh)))\n",
    "\n",
    "    if len(centers) > 0:\n",
    "        # change the given value of 2.15 according to the size of the detected face\n",
    "        glasses_width = 2.16 * abs(centers[1][0] - centers[0][0])\n",
    "        overlay_img = np.ones(image.shape, np.uint8) * 255\n",
    "        h, w = glass_img.shape[:2]\n",
    "        scaling_factor = glasses_width / w\n",
    "\n",
    "        overlay_glasses = cv2.resize(glass_img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        x = centers[0][0] if centers[0][0] < centers[1][0] else centers[1][0]\n",
    "\n",
    "        # The x and y variables below depend upon the size of the detected face.\n",
    "        x -= 0.25 * overlay_glasses.shape[1]\n",
    "        y += 1.1 * overlay_glasses.shape[0]\n",
    "\n",
    "        # Slice the height, width of the overlay image.\n",
    "        h, w = overlay_glasses.shape[:2]\n",
    "        overlay_img[int(y):int(y + h), int(x):int(x + w)] = overlay_glasses\n",
    "\n",
    "        # Create a mask and generate it's inverse.\n",
    "        gray_glasses = cv2.cvtColor(overlay_img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, mask = cv2.threshold(gray_glasses, 110, 255, cv2.THRESH_BINARY)\n",
    "        mask_inv = cv2.bitwise_not(mask)\n",
    "        temp = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "        temp2 = cv2.bitwise_and(overlay_img, overlay_img, mask=mask_inv)\n",
    "        final_img = cv2.add(temp, temp2)\n",
    "        \n",
    "        #save the new images in new dir\n",
    "        cv2.imwrite(os.path.join(SAVE_DIR,file), final_img)\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
